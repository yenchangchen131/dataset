# ç¹é«”ä¸­æ–‡ RAG æ•ˆèƒ½è©•æ¸¬å¾®å‹è³‡æ–™é›† (Micro-Scale TC-RAG Benchmark)

é€™æ˜¯ä¸€å€‹è¼•é‡ç´šã€é‡å°ç¹é«”ä¸­æ–‡ RAG (Retrieval-Augmented Generation) ç³»çµ±è¨­è¨ˆçš„è©•æ¸¬è³‡æ–™é›†ã€‚é€éå¾å­¸è¡“ç•Œæ¨™æº–è³‡æ–™é›† (DRCD, SQuAD, HotpotQA, 2WikiMultiHopQA) é€²è¡Œæ¡æ¨£èˆ‡é«˜å“è³ªç¿»è­¯ï¼Œå»ºç«‹ä¸€å€‹åŒ…å« **50 é¡Œå•ç­” (Queries)** èˆ‡ **500 ç¯‡æ–‡æª” (Corpus)** çš„æ¸¬è©¦åŸºæº–ã€‚

## ğŸ¯ å°ˆæ¡ˆç›®æ¨™

- **è¼•é‡åŒ–**ï¼šåƒ… 50 é¡Œï¼Œå¯å¿«é€Ÿé©—è­‰ç³»çµ±æ•ˆèƒ½ã€‚
- **åœ¨åœ°åŒ–**ï¼šå…¨æ•¸è³‡æ–™çš†ç‚ºå°ç£ç¹é«”ä¸­æ–‡ (Traditional Chinese, Taiwan)ã€‚
- **é«˜é‘‘åˆ¥åº¦**ï¼šåŒ…å«å–®è·³ (Single-hop) èˆ‡å¤šè·³ (Multi-hop) æ¨ç†é¡Œå‹ï¼Œä¸¦æ··å…¥èˆ‡æ­£è§£é«˜åº¦ç›¸ä¼¼çš„å¹²æ“¾æ–‡æª” (Hard Negatives)ã€‚

## ğŸ“Š è³‡æ–™é›†çµ±è¨ˆ

| ä¾†æºè³‡æ–™é›† | é¡Œå‹ | æ•¸é‡ | èªªæ˜ |
|------------|------|------|------|
| **DRCD** | å–®è·³ | 15 | åŸç”Ÿç¹é«”ä¸­æ–‡è³‡æ–™ |
| **SQuAD** | å–®è·³ | 15 | è‹±æ–‡ç¿»è­¯ç‚ºç¹ä¸­ |
| **HotpotQA** | å¤šè·³ | 10 | è‹±æ–‡ç¿»è­¯ç‚ºç¹ä¸­ (å«å¹²æ“¾é …) |
| **2Wiki** | å¤šè·³ | 10 | è‹±æ–‡ç¿»è­¯ç‚ºç¹ä¸­ (å«å¹²æ“¾é …) |
| **ç¸½è¨ˆ** | - | **50** | |

- **æ–‡æª”åº« (Corpus)**: ç¸½è¨ˆ **500 ç¯‡**
  - **Gold Contexts**: ~70 ç¯‡ (æ­£è§£)
  - **Negatives**: ~430 ç¯‡ (åŒ…å« Hard/Random Negatives)

## ğŸ› ï¸ å®‰è£èˆ‡ç’°å¢ƒè¨­å®š

æœ¬å°ˆæ¡ˆä½¿ç”¨ `uv` é€²è¡Œå¥—ä»¶ç®¡ç†ã€‚

1. **å®‰è£ç›¸ä¾å¥—ä»¶**
   ```bash
   uv sync
   ```
   æˆ–æ‰‹å‹•å®‰è£ï¼š
   ```bash
   uv add openai python-dotenv tqdm
   ```

2. **è¨­å®šç’°å¢ƒè®Šæ•¸**
   è«‹åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„å»ºç«‹ `.env` æª”æ¡ˆï¼Œä¸¦å¡«å…¥ OpenAI API Key (ç”¨æ–¼ç¿»è­¯èˆ‡ä¿®å¾©)ï¼š
   ```ini
   OPENAI_API_KEY=sk-your-api-key-here
   ```

## ğŸš€ ä½¿ç”¨æŒ‡å— (Pipeline)

è«‹ä¾åºåŸ·è¡Œä»¥ä¸‹è…³æœ¬ä»¥ç”¢ç”Ÿè³‡æ–™é›†ï¼š

### 0. è³‡æ–™ä¸‹è¼‰
ä¸‹è¼‰åŸå§‹è³‡æ–™é›† (DRCD, SQuAD, HotpotQA, 2WikiMultiHopQA) è‡³ `data/raw/` ç›®éŒ„ã€‚
```bash
uv run src/data_download.py
```

### 1. è³‡æ–™æå–èˆ‡æ¡æ¨£
å¾ `data/raw/` è®€å–åŸå§‹è³‡æ–™ï¼Œä¾ç…§è¨­å®šæ¯”ä¾‹æ¡æ¨£ï¼Œä¸¦çµ„è£æ–‡æª”æ± ã€‚
```bash
uv run src/process_data.py
```
> ç”¢å‡ºï¼š`data/processed/queries_raw.json`, `data/processed/corpus_raw.json`

### 2. ä¸¦è¡Œç¿»è­¯ (è‹±ç¿»ä¸­)
ä½¿ç”¨ GPT-4o-mini å¤šåŸ·è¡Œç·’å°‡è‹±æ–‡è³‡æ–™ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚
```bash
uv run src/translate_data.py
```
> ç”¢å‡ºï¼š`data/processed/queries.json`, `data/processed/corpus.json`

### 3. å•é¡Œä¿®å¾©
é‡å°ç¿»è­¯éç¨‹ä¸­å¯èƒ½æ®˜ç•™çš„è‹±æ–‡é™³è¿°å¥ï¼Œé€éèªæ„æ”¹å¯«ä¿®æ­£ç‚ºä¸­æ–‡å•å¥ã€‚
```bash
uv run src/fix_questions.py
```

### 4. è³‡æ–™é©—è­‰
æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§ã€æ•¸é‡ã€Schema èˆ‡èªè¨€ä¸€è‡´æ€§ã€‚
```bash
uv run src/verify_data.py
```

## ğŸ“‚ æª”æ¡ˆçµæ§‹

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # åŸå§‹ä¸‹è¼‰çš„è³‡æ–™é›†
â”‚   â””â”€â”€ processed/         # ç”¢å‡ºçš„æœ€çµ‚è³‡æ–™é›†
â”‚       â”œâ”€â”€ queries.json   # è©•æ¸¬é¡Œåº« (50é¡Œ)
â”‚       â””â”€â”€ corpus.json    # æ–‡æª”åº« (500ç¯‡)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_download.py   # [Step 0] åŸå§‹è³‡æ–™ä¸‹è¼‰
â”‚   â”œâ”€â”€ process_data.py    # [Step 1] æ¡æ¨£èˆ‡æå–
â”‚   â”œâ”€â”€ translate_data.py  # [Step 2] ç¿»è­¯
â”‚   â”œâ”€â”€ fix_questions.py   # [Step 3] å•é¡Œä¿®å¾©
â”‚   â”œâ”€â”€ verify_data.py     # [Step 4] é©—è­‰
â”‚   â””â”€â”€ inspect_suspicious.py # (å·¥å…·) æª¢è¦–ç•°å¸¸è³‡æ–™
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ Spec.md            # è©³ç´°è¦æ ¼æ›¸
â”œâ”€â”€ .env                   # API Key è¨­å®šæª”
â””â”€â”€ README.md              # æœ¬æ–‡ä»¶
```

## ğŸ“ è¼¸å‡ºæ ¼å¼

### Query (`queries.json`)
```json
{
  "question_id": "uuid...",
  "question": "ç¹é«”ä¸­æ–‡å•é¡Œ...",
  "gold_answer": "æ¨™æº–ç­”æ¡ˆ",
  "gold_doc_ids": ["doc_uuid_1", "doc_uuid_2"],
  "source_dataset": "hotpotqa",
  "question_type": "multi-hop"
}
```

### Corpus (`corpus.json`)
```json
{
  "doc_id": "doc_uuid...",
  "content": "ç¹é«”ä¸­æ–‡æ–‡ç« å…§å®¹...",
  "original_source": "hotpotqa",
  "original_id": "origin_id...", 
  "is_gold": true
}
```
